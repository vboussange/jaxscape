{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a93e95",
   "metadata": {},
   "source": [
    "# Inverse landscape genetics\n",
    "\n",
    "Traditional landscape genetics assumes *a priori* which habitat features facilitate or impede movement. Inverse landscape genetics reverses this approach, inferring permeability patterns directly from genetic data. This notebook demonstrates fitting a neural network to predict landscape resistance from land-cover features, optimizing the model to match observed genetic differentiation (Fst) between sampling sites.\n",
    "\n",
    "We use genetic data from the [Mountain Pygmy-possum](https://en.wikipedia.org/wiki/Mountain_pygmy_possum) (*Burramys parvus*), an endangered marsupial endemic to alpine regions of southeastern Australia, kindly provided by [Cesar Australia](https://cesaraustralia.com). We'll use land-cover data to model landscape permeability and fit the model to observed genetic distances, obtained from ESA WorldCover.\n",
    "<!-- TODO: update link -->\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://www.australiangeographic.com.au/wp-content/uploads/2018/06/Pygmy-Possum_Amanda-McLean-Copy-1.jpg\" width=\"450\">\n",
    "</div>\n",
    "\n",
    "### Prerequisites\n",
    "```bash\n",
    "pip install jaxscape equinox optimistix rioxarray geopandas scikit-learn\n",
    "```\n",
    "\n",
    " We've prepared the data for you to focus on the modeling aspects; you can download the dataset [here](https://vboussange.github.io/jaxscape/data/inverse_landscape_genetics/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf6b56e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rioxarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrioxarray\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxarray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxr\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgeopandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgpd\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'rioxarray'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import equinox as eqx\n",
    "from equinox import nn\n",
    "import optimistix as optx\n",
    "\n",
    "from jaxscape import GridGraph, ResistanceDistance, LCPDistance\n",
    "from jaxscape.solvers import CholmodSolver\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9326b97",
   "metadata": {},
   "source": [
    "### Configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008aa775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths (adjust to your data location)\n",
    "LANDCOVER_PATH = '../data/cesar/landcover_7855.tif'\n",
    "SITE_METADATA_PATH = '../data/cesar/cesar_site_metadata.gpkg'\n",
    "GENETIC_DISTANCES_PATH = '../data/cesar/cesar_genetic_distances.npy'\n",
    "\n",
    "# Model configuration\n",
    "COARSENING_FACTOR = 10  # Spatial downsampling of feature raster to accelerate computation\n",
    "SOLVER = CholmodSolver()  # Fast linear solver for large graphs\n",
    "DISTANCE_FUN = ResistanceDistance(solver=SOLVER)  # Effective resistance distance\n",
    "MAX_STEPS = 500  # Maximum optimization iterations\n",
    "\n",
    "# Alternative distance metric for experimentation:\n",
    "# DISTANCE_FUN = LCPDistance()  # Least-cost path distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1273f760",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load land-cover raster\n",
    "predictor_raster = rioxarray.open_rasterio(\n",
    "    LANDCOVER_PATH, \n",
    "    mask_and_scale=True\n",
    ")\n",
    "\n",
    "# Load site metadata (geographic locations)\n",
    "site_metadata = gpd.read_file(SITE_METADATA_PATH)\n",
    "site_gdf = site_metadata.to_crs(epsg=7855)  # Reproject to Australian GDA2020\n",
    "\n",
    "# Load genetic distance matrix\n",
    "genetic_distances = np.load(GENETIC_DISTANCES_PATH)\n",
    "\n",
    "print(f\"Land-cover raster shape: {predictor_raster['band_1'].shape}\")\n",
    "print(f\"Number of sites: {len(site_gdf)}\")\n",
    "print(f\"Genetic distance matrix shape: {genetic_distances.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da822373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize land-cover with sampling sites\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "predictor_raster[\"band_1\"].plot(ax=ax, cmap=\"tab20\", add_colorbar=True)\n",
    "ax.scatter(\n",
    "    site_gdf.geometry.x, \n",
    "    site_gdf.geometry.y, \n",
    "    c=\"red\", \n",
    "    s=100, \n",
    "    edgecolor='white',\n",
    "    linewidth=2,\n",
    "    label=\"Sampling Sites\",\n",
    "    zorder=10\n",
    ")\n",
    "ax.set_title(\"Land-Cover Map with Sampling Sites\", fontsize=14, pad=20)\n",
    "ax.legend(loc='upper right', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Sites: {', '.join(site_gdf['site_name'].values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de563334",
   "metadata": {},
   "source": [
    "## Prepare features and targets\n",
    "\n",
    "The land-cover raster requires preprocessing before feeding it to the neural network. We first compress the sparse WorldCover class IDs into a contiguous range (0..K-1), then one-hot encode them into binary feature vectors. Spatial coarsening via mean pooling downsamples the raster while preserving land-cover composition within each aggregated cell, capturing habitat heterogeneity without forcing discrete classifications. Finally, we map each sampling site to its nearest grid cell in the coarsened raster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a975a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_feature_targets(predictor_raster, site_gdf, coarsening_factor):\n",
    "    \"\"\"Process land-cover and create model inputs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    features_onehot_coarse : array\n",
    "        One-hot encoded land-cover features after coarsening (H, W, K)\n",
    "    unique_classes : array\n",
    "        Original WorldCover class values\n",
    "    target_nodes : array\n",
    "        Node indices for sampling sites\n",
    "    grid : GridGraph\n",
    "        Reference grid for node indexing\n",
    "    feature_da : xarray.DataArray\n",
    "        Coarsened feature raster with coordinates\n",
    "    \"\"\"\n",
    "    # Compress WorldCover classes to contiguous IDs\n",
    "    raw_band = np.asarray(predictor_raster[\"band_1\"])\n",
    "    unique_vals, inverse = np.unique(raw_band.ravel(), return_inverse=True)\n",
    "    class_ids = inverse.reshape(raw_band.shape).astype(np.int32)\n",
    "    features_categorical = jnp.array(class_ids).squeeze()\n",
    "    unique_classes = jnp.array(unique_vals)\n",
    "    \n",
    "    print(f\"Found {len(unique_vals)} unique land-cover classes\")\n",
    "    \n",
    "    # One-hot encode: (H, W) -> (H, W, K)\n",
    "    features_onehot = jax.nn.one_hot(\n",
    "        features_categorical, \n",
    "        num_classes=len(unique_vals)\n",
    "    )\n",
    "    \n",
    "    # Reorder for coarsening: (H, W, K) -> (K, H, W)\n",
    "    features_onehot = jnp.moveaxis(features_onehot, -1, 0)\n",
    "    \n",
    "    # Coarsen using mean pooling (preserves class composition)\n",
    "    coords = {\n",
    "        \"band\": np.arange(features_onehot.shape[0]),\n",
    "        \"y\": predictor_raster.y.values,\n",
    "        \"x\": predictor_raster.x.values,\n",
    "    }\n",
    "    feature_da = xr.DataArray(\n",
    "        features_onehot,\n",
    "        coords=coords,\n",
    "        dims=(\"band\", \"y\", \"x\"),\n",
    "    )\n",
    "    feature_da = feature_da.coarsen(\n",
    "        x=coarsening_factor, \n",
    "        y=coarsening_factor, \n",
    "        boundary=\"trim\"\n",
    "    ).mean()\n",
    "    \n",
    "    # Back to (H, W, K)\n",
    "    features_onehot_coarse = jnp.moveaxis(feature_da.data, 0, -1)\n",
    "    print(f\"Coarsened feature shape: {features_onehot_coarse.shape}\")\n",
    "    \n",
    "    # Map site coordinates to coarsened grid indices\n",
    "    x_idx = jnp.array([\n",
    "        int(np.argmin(np.abs(feature_da.x.values - x))) \n",
    "        for x in site_gdf.geometry.x.values\n",
    "    ])\n",
    "    y_idx = jnp.array([\n",
    "        int(np.argmin(np.abs(feature_da.y.values - y))) \n",
    "        for y in site_gdf.geometry.y.values\n",
    "    ])\n",
    "    \n",
    "    # Create reference grid for node indexing\n",
    "    grid = GridGraph(\n",
    "        jnp.ones((feature_da.x.size, feature_da.y.size)), \n",
    "        fun=lambda x, y: (x + y) / 2\n",
    "    )\n",
    "    target_nodes = grid.coord_to_index(x_idx, y_idx)\n",
    "    \n",
    "    return features_onehot_coarse, unique_classes, target_nodes, grid, feature_da\n",
    "\n",
    "# Process features\n",
    "features_onehot, unique_classes, target_nodes, ref_grid, coarse_feature_da = prepare_feature_targets(\n",
    "    predictor_raster, site_gdf, COARSENING_FACTOR\n",
    ")\n",
    "\n",
    "print(f\"Target nodes (site indices): {target_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coarsened land-cover with sites\n",
    "node_coords = ref_grid.index_to_coord(target_nodes)\n",
    "x_indices, y_indices = node_coords[:, 0], node_coords[:, 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "ax.imshow(features_onehot.argmax(axis=-1), cmap=\"tab20\")\n",
    "ax.scatter(\n",
    "    x_indices, y_indices, \n",
    "    c=\"blue\", \n",
    "    s=150, \n",
    "    edgecolor='white',\n",
    "    linewidth=2,\n",
    "    label=\"Sites\",\n",
    "    zorder=10\n",
    ")\n",
    "\n",
    "# Annotate sites\n",
    "for xi, yi, name in zip(x_indices, y_indices, site_gdf[\"site_name\"].values):\n",
    "    ax.text(\n",
    "        int(xi), int(yi) - 5,\n",
    "        str(name),\n",
    "        color=\"black\",\n",
    "        fontsize=10,\n",
    "        fontweight='bold',\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        bbox=dict(facecolor=\"white\", alpha=0.9, edgecolor=\"black\", pad=2),\n",
    "    )\n",
    "\n",
    "ax.set_title(\"Coarsened Land-Cover with Site Locations\", fontsize=14, pad=20)\n",
    "ax.legend(loc='upper right', fontsize=12)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31611502",
   "metadata": {},
   "source": [
    "## Define the permeability model\n",
    "\n",
    "We build a neural network mapping one-hot land-cover features to positive permeability values: $\\text{permeability} = \\exp(\\text{NN}(\\text{features})) + \\epsilon$. The architecture takes a K-dimensional one-hot vector (land-cover classes), passes it through two hidden layers with ReLU activation (16 units each), and outputs a single value that is exponentiated to ensure positivity. We apply this model pixel-wise via `vmap` to generate the full permeability surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9644ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes: int, seed: int = 1) -> tuple:\n",
    "    \"\"\"Build neural permeability model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_classes : int\n",
    "        Number of land-cover classes\n",
    "    seed : int\n",
    "        Random seed for initialization\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model : eqx.Module\n",
    "        Complete model\n",
    "    params : pytree\n",
    "        Trainable parameters\n",
    "    static : pytree\n",
    "        Static (non-trainable) components\n",
    "    \"\"\"\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    \n",
    "    class PermeabilityModel(eqx.Module):\n",
    "        layers: list\n",
    "        num_classes: int\n",
    "        \n",
    "        def __init__(self, num_classes: int, key):\n",
    "            self.num_classes = num_classes\n",
    "            k1, k2, k3 = jax.random.split(key, 3)\n",
    "            hidden_dim = 16  # Small network to prevent overfitting\n",
    "            \n",
    "            self.layers = [\n",
    "                nn.Linear(num_classes, hidden_dim, key=k1),\n",
    "                jax.nn.relu,\n",
    "                nn.Linear(hidden_dim, hidden_dim, key=k2),\n",
    "                jax.nn.relu,\n",
    "                nn.Linear(hidden_dim, 1, key=k3),\n",
    "            ]\n",
    "        \n",
    "        def __call__(self, x):\n",
    "            \"\"\"Map one-hot feature to positive permeability.\"\"\"\n",
    "            for layer in self.layers:\n",
    "                x = layer(x)\n",
    "            return jnp.exp(x) + 1e-3  # Ensure positive permeability\n",
    "    \n",
    "    model = PermeabilityModel(num_classes, key)\n",
    "    params, static = eqx.partition(model, eqx.is_inexact_array)\n",
    "    return model, params, static\n",
    "\n",
    "# Initialize model\n",
    "model, params, static = build_model(len(unique_classes))\n",
    "print(f\"Model initialized with {len(unique_classes)} land-cover classes\")\n",
    "print(f\"Trainable parameters: {sum(p.size for p in jax.tree_util.tree_leaves(params))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8b4ca0",
   "metadata": {},
   "source": [
    "Before training, the model produces random permeability values based on the initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1512f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply model to all pixels via vmap\n",
    "model_vmapped = jax.vmap(jax.vmap(model, in_axes=0), in_axes=0)\n",
    "initial_permeability = model_vmapped(features_onehot).squeeze()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "im = ax.imshow(initial_permeability, cmap=\"RdYlGn_r\")\n",
    "ax.set_title(\"Initial permeability Prediction (Random)\", fontsize=14, pad=20)\n",
    "ax.axis(\"off\")\n",
    "plt.colorbar(im, ax=ax, label=\"Permeability\", shrink=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b61c48",
   "metadata": {},
   "source": [
    "## Define loss function and training setup\n",
    "\n",
    "We minimize mean squared error (MSE) between predicted resistance distances and observed genetic distances. The training loop predicts pixel-wise permeability, constructs a GridGraph, computes pairwise resistance distances between sampling sites, and backpropagates gradients through the entire pipeline using L-BFGS optimization.\n",
    "\n",
    "We split pairwise distances (upper triangle of the matrix) into 80% training and 20% test sets to evaluate generalization. This train/test split reveals whether the model learns meaningful permeability patterns or simply memorizes training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de211b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract upper triangle indices (all unique pairs)\n",
    "n_sites = genetic_distances.shape[0]\n",
    "tri_i_all, tri_j_all = np.triu_indices(n_sites, k=1)\n",
    "target_flat_all = np.asarray(genetic_distances)[tri_i_all, tri_j_all]\n",
    "\n",
    "print(f\"Total pairwise distances: {len(target_flat_all)}\")\n",
    "\n",
    "# Train/test split (80/20)\n",
    "(\n",
    "    target_flat_train,\n",
    "    target_flat_test,\n",
    "    tri_i_train,\n",
    "    tri_i_test,\n",
    "    tri_j_train,\n",
    "    tri_j_test,\n",
    ") = train_test_split(\n",
    "    target_flat_all,\n",
    "    tri_i_all,\n",
    "    tri_j_all,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Convert to JAX arrays for training\n",
    "tri_i_train = jnp.array(tri_i_train)\n",
    "tri_j_train = jnp.array(tri_j_train)\n",
    "tri_i_test = np.array(tri_i_test)\n",
    "tri_j_test = np.array(tri_j_test)\n",
    "\n",
    "print(f\"Training pairs: {len(target_flat_train)}\")\n",
    "print(f\"Test pairs: {len(target_flat_test)}\")\n",
    "\n",
    "# Sanity check: compute initial loss\n",
    "initial_loss = loss_fn(\n",
    "    params, \n",
    "    (static, features_onehot, target_flat_train, tri_i_train, tri_j_train)\n",
    ")\n",
    "print(f\"\\nInitial training loss: {initial_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def loss_fn(params, args):\n",
    "    \"\"\"Compute squared error between predicted and target distances.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params : pytree\n",
    "        Trainable model parameters\n",
    "    args : tuple\n",
    "        (static, features, target_flat_train, tri_i_train, tri_j_train)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    loss : float\n",
    "        Mean squared error on training pairs\n",
    "    \"\"\"\n",
    "    static, features, target_flat_train, tri_i_train, tri_j_train = args\n",
    "    \n",
    "    # Reconstruct model and predict permeability surface\n",
    "    model = eqx.combine(params, static)\n",
    "    model_vmapped = jax.vmap(jax.vmap(model, in_axes=0), in_axes=0)\n",
    "    permeability = model_vmapped(features).squeeze()\n",
    "    \n",
    "    # Build graph and compute permeability distances\n",
    "    grid = GridGraph(permeability, fun=lambda x, y: (x + y) / 2)\n",
    "    predicted_distances = DISTANCE_FUN(grid, nodes=target_nodes)\n",
    "    \n",
    "    # Extract training pairs and compute loss\n",
    "    pred_flat_train = predicted_distances[tri_i_train, tri_j_train]\n",
    "    return ((target_flat_train - pred_flat_train) ** 2).mean()\n",
    "\n",
    "print(\"Loss function defined and JIT-compiled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153fc00a",
   "metadata": {},
   "source": [
    "## Training\n",
    "The optimization typically takes several minutes depending on graph size and the number of iterations required for convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db11870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure L-BFGS optimizer\n",
    "solver = optx.LBFGS(\n",
    "    rtol=1e-5,  # Relative tolerance for convergence\n",
    "    atol=1e-5,  # Absolute tolerance\n",
    "    verbose=frozenset({\"loss\"})  # Print loss during optimization\n",
    ")\n",
    "\n",
    "print(\"Starting optimization...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_train_time = time.time()\n",
    "\n",
    "# Run optimization\n",
    "opt_solution = optx.minimise(\n",
    "    loss_fn,\n",
    "    solver,\n",
    "    params,\n",
    "    args=(static, features_onehot, target_flat_train, tri_i_train, tri_j_train),\n",
    "    max_steps=MAX_STEPS,\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_train_time\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n✓ Training completed in {training_time:.2f} seconds\")\n",
    "print(f\"Final loss: {opt_solution.value:.6f}\")\n",
    "print(f\"\\nOptimization statistics:\")\n",
    "print(opt_solution.stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd0ed2a",
   "metadata": {},
   "source": [
    "### Visualize the learned permeability surface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted distances using fitted permeability\n",
    "pred_grid = GridGraph(fitted_permeability, fun=lambda x, y: (x + y) / 2)\n",
    "pred_distances = DISTANCE_FUN(pred_grid, nodes=target_nodes)\n",
    "\n",
    "genetic_np = np.asarray(genetic_distances)\n",
    "pred_np = np.asarray(pred_distances)\n",
    "\n",
    "# Extract predictions for train and test pairs\n",
    "train_pred = pred_np[tri_i_train, tri_j_train]\n",
    "test_pred = pred_np[tri_i_test, tri_j_test]\n",
    "train_target = target_flat_train\n",
    "test_target = target_flat_test\n",
    "\n",
    "# Compute metrics\n",
    "r2_train = r2_score(train_target, train_pred)\n",
    "r2_test = r2_score(test_target, test_pred)\n",
    "rmse_train = np.sqrt(mean_squared_error(train_target, train_pred))\n",
    "rmse_test = np.sqrt(mean_squared_error(test_target, test_pred))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 8))\n",
    "\n",
    "# Plot training and test predictions\n",
    "ax.scatter(\n",
    "    train_pred, train_target, \n",
    "    s=60, alpha=0.6, \n",
    "    edgecolor=\"none\", \n",
    "    label=\"Training\",\n",
    "    c='#2E86AB'\n",
    ")\n",
    "ax.scatter(\n",
    "    test_pred, test_target, \n",
    "    s=80, alpha=0.8, \n",
    "    edgecolor=\"black\",\n",
    "    linewidth=1,\n",
    "    label=\"Test\",\n",
    "    c='#A23B72'\n",
    ")\n",
    "\n",
    "# 1:1 reference line\n",
    "min_val = min(pred_np.min(), genetic_np.min())\n",
    "max_val = max(pred_np.max(), genetic_np.max())\n",
    "ax.plot(\n",
    "    [min_val, max_val], [min_val, max_val], \n",
    "    \"k--\", linewidth=2, \n",
    "    alpha=0.5,\n",
    "    label=\"Perfect fit (1:1)\"\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Predicted Resistance Distance\", fontsize=12)\n",
    "ax.set_ylabel(\"Observed Genetic Distance (Fst)\", fontsize=12)\n",
    "ax.set_title(\n",
    "    \"Inverse Landscape Model: Predicted vs. Observed\", \n",
    "    fontsize=14, \n",
    "    pad=20\n",
    ")\n",
    "\n",
    "# Add metrics box\n",
    "textstr = (\n",
    "    f\"Training\\n\"\n",
    "    f\"  R² = {r2_train:.3f}\\n\"\n",
    "    f\"  RMSE = {rmse_train:.4f}\\n\\n\"\n",
    "    f\"Test\\n\"\n",
    "    f\"  R² = {r2_test:.3f}\\n\"\n",
    "    f\"  RMSE = {rmse_test:.4f}\"\n",
    ")\n",
    "ax.text(\n",
    "    0.05, 0.95,\n",
    "    textstr,\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=10,\n",
    "    verticalalignment=\"top\",\n",
    "    bbox=dict(\n",
    "        boxstyle=\"round\", \n",
    "        facecolor=\"white\", \n",
    "        alpha=0.9, \n",
    "        edgecolor=\"gray\",\n",
    "        linewidth=1.5\n",
    "    ),\n",
    ")\n",
    "\n",
    "ax.legend(loc=\"lower right\", fontsize=11, framealpha=0.9)\n",
    "ax.grid(True, alpha=0.3, linestyle=':')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf7fb7b",
   "metadata": {},
   "source": [
    "Our model seems to perform reasonably well, capturing a significant portion of the variance in genetic distances. \n",
    "We can now visualize the learned permeability patterns across the landscape. Remember that this is to be interpreted with great caution, as the inferred permeability surface may reflect complex interactions and correlations in the data rather than direct causal relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd42b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply fitted model to landscape\n",
    "fitted_model = eqx.combine(opt_solution.value, static)\n",
    "fitted_vmapped = jax.vmap(jax.vmap(fitted_model, in_axes=0), in_axes=0)\n",
    "fitted_permeability = fitted_vmapped(features_onehot).squeeze()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Initial (random) permeability\n",
    "im1 = ax1.imshow(initial_permeability, cmap=\"RdYlGn_r\")\n",
    "ax1.set_title(\"Initial permeability surface\", fontsize=13, pad=15)\n",
    "ax1.axis(\"off\")\n",
    "plt.colorbar(im1, ax=ax1, shrink=0.6, label=\"Permeability\")\n",
    "\n",
    "# Fitted permeability\n",
    "im2 = ax2.imshow(fitted_permeability, cmap=\"RdYlGn_r\")\n",
    "ax2.set_title(\"Fitted permeability surface (Trained)\", fontsize=13, pad=15)\n",
    "ax2.axis(\"off\")\n",
    "plt.colorbar(im2, ax=ax2, shrink=0.6, label=\"Permeability\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fitted permeability range: [{fitted_permeability.min():.3f}, {fitted_permeability.max():.3f}]\")\n",
    "print(f\"Mean permeability: {fitted_permeability.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0841757",
   "metadata": {},
   "source": [
    "## Key takeaways\n",
    "\n",
    "This notebook demonstrated inverse landscape genetics: learning resistance patterns from genetic data rather than assuming them *a priori*. JAX's automatic differentiation enables gradient-based optimization, allowing to train neural networks to map landscape features to a permeability surface. Neural networks provide flexible parameterization capturing nonlinear landscape feature–permeability relationships. It would be interesting to compare this learned resistance surface with expert knowledge about the species' ecology and known barriers to movement in the landscape. We could also assess the predictive performance of e.g. the `LCPDistance`. But this goes beyond the scope of this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxscape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
